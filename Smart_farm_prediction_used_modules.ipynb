{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_sf = pd.read_csv('Smart_Farm_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-95a9242fbcd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DO ANY PRE OBSERVATION HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_sf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sf' is not defined"
     ]
    }
   ],
   "source": [
    "# DO ANY PRE OBSERVATION HERE\n",
    "\n",
    "df_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT REPRESENT (PREVIOUSLY) STRING ENCODED LOC AND GEN COLUMNS\n",
    "\n",
    "df_sf = pd.concat([df_sf, pd.get_dummies(df_sf['Loc'])], axis=1)\n",
    "df_sf = pd.concat([df_sf, pd.get_dummies(df_sf['Gen'])], axis=1)\n",
    "\n",
    "# DROP ANY COLUMNS HERE\n",
    "COLUMNS_DROPPED = ['Date', 'Loc', 'Gen', 'PlantID']\n",
    "df_sf = df_sf.drop(COLUMNS_DROPPED, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf.loc[90:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS MODULE WILL SPLIT UP EACH 100 POINTS IN THE DATAFRAME INTO SEPARATE CYCLES SO THAT WE CAN DO TIME SHIFTING\n",
    "# ON THE APPROPRIATE CYCLES\n",
    "cycles = []\n",
    "for i in range(0, 4):\n",
    "    start_index = i*100\n",
    "    end_index = start_index + 99\n",
    "    df_cycle = df_sf.loc[start_index:end_index]\n",
    "    cycles.append(df_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.reset_index().drop(['index'], axis=1).to_csv('reindexed_output_shifted_cycles.csv')\n",
    "new_data = data.reset_index().drop(['index'], axis=1)\n",
    "X_train = new_data.loc[0:84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(0,5)] + [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_data.iloc[[i for i in range(0,85)]\n",
    "                        + [i for i in range(90,175)]\n",
    "                        + [i for i in range(180, 265)]\n",
    "                        + [i for i in range(270,355)]]\n",
    "y_train = X_train.loc[:, 'var2(t)']\n",
    "X_train = X_train.loc[:,~data.columns.str.contains('\\(t\\)')]\n",
    "# X = data.drop([data.columns.str.contains('\\(t\\)')], axis=1)\n",
    "X_test = new_data.iloc[[i for i in range(85,90)]\n",
    "                        + [i for i in range(175,180)]\n",
    "                        + [i for i in range(265,270)]\n",
    "                        + [i for i in range(355, 360)]]\n",
    "y_test = X_test.loc[:, 'var2(t)']\n",
    "X_test = X_test.loc[:,~data.columns.str.contains('\\(t\\)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var2(t-10)</th>\n",
       "      <th>var3(t-10)</th>\n",
       "      <th>var4(t-10)</th>\n",
       "      <th>var5(t-10)</th>\n",
       "      <th>var6(t-10)</th>\n",
       "      <th>var7(t-10)</th>\n",
       "      <th>var8(t-10)</th>\n",
       "      <th>var9(t-10)</th>\n",
       "      <th>var10(t-10)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86.0</td>\n",
       "      <td>6.670000e-05</td>\n",
       "      <td>95.0</td>\n",
       "      <td>23.47</td>\n",
       "      <td>61.17</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.270000e-07</td>\n",
       "      <td>76.0</td>\n",
       "      <td>25.06</td>\n",
       "      <td>67.93</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87.0</td>\n",
       "      <td>3.330000e-05</td>\n",
       "      <td>90.0</td>\n",
       "      <td>24.05</td>\n",
       "      <td>58.65</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.330000e-08</td>\n",
       "      <td>83.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>67.36</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88.0</td>\n",
       "      <td>1.660000e-05</td>\n",
       "      <td>83.0</td>\n",
       "      <td>23.69</td>\n",
       "      <td>62.14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.160000e-08</td>\n",
       "      <td>82.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>64.60</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89.0</td>\n",
       "      <td>8.270000e-06</td>\n",
       "      <td>92.0</td>\n",
       "      <td>23.58</td>\n",
       "      <td>60.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.570000e-08</td>\n",
       "      <td>89.0</td>\n",
       "      <td>25.56</td>\n",
       "      <td>69.67</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90.0</td>\n",
       "      <td>4.120000e-06</td>\n",
       "      <td>96.0</td>\n",
       "      <td>24.34</td>\n",
       "      <td>65.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.850000e-09</td>\n",
       "      <td>89.0</td>\n",
       "      <td>29.70</td>\n",
       "      <td>81.26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.140000e-07</td>\n",
       "      <td>95.0</td>\n",
       "      <td>23.47</td>\n",
       "      <td>61.17</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.300000e-10</td>\n",
       "      <td>76.0</td>\n",
       "      <td>25.06</td>\n",
       "      <td>67.93</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>87.0</td>\n",
       "      <td>2.050000e-07</td>\n",
       "      <td>90.0</td>\n",
       "      <td>24.05</td>\n",
       "      <td>58.65</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.180000e-11</td>\n",
       "      <td>83.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>67.36</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>88.0</td>\n",
       "      <td>8.160000e-08</td>\n",
       "      <td>83.0</td>\n",
       "      <td>23.69</td>\n",
       "      <td>62.14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.060000e-11</td>\n",
       "      <td>82.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>64.60</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>89.0</td>\n",
       "      <td>3.250000e-08</td>\n",
       "      <td>92.0</td>\n",
       "      <td>23.58</td>\n",
       "      <td>60.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8.220000e-12</td>\n",
       "      <td>89.0</td>\n",
       "      <td>25.56</td>\n",
       "      <td>69.67</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>90.0</td>\n",
       "      <td>1.300000e-08</td>\n",
       "      <td>96.0</td>\n",
       "      <td>24.34</td>\n",
       "      <td>65.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.280000e-12</td>\n",
       "      <td>89.0</td>\n",
       "      <td>29.70</td>\n",
       "      <td>81.26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>86.0</td>\n",
       "      <td>6.157151e+00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>35.89</td>\n",
       "      <td>38.49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.222748e-01</td>\n",
       "      <td>83.0</td>\n",
       "      <td>34.74</td>\n",
       "      <td>51.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>87.0</td>\n",
       "      <td>6.602047e+00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>35.14</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.274950e-02</td>\n",
       "      <td>87.0</td>\n",
       "      <td>35.60</td>\n",
       "      <td>49.24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>88.0</td>\n",
       "      <td>6.971920e+00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>35.28</td>\n",
       "      <td>24.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.049128e-02</td>\n",
       "      <td>89.0</td>\n",
       "      <td>34.13</td>\n",
       "      <td>42.74</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>89.0</td>\n",
       "      <td>7.078277e+00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>34.67</td>\n",
       "      <td>26.89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.119251e-02</td>\n",
       "      <td>93.0</td>\n",
       "      <td>36.76</td>\n",
       "      <td>68.52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>90.0</td>\n",
       "      <td>6.547096e+00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.06</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.102686e-03</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.08</td>\n",
       "      <td>64.36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.234138e+00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>35.89</td>\n",
       "      <td>38.49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.419863e-01</td>\n",
       "      <td>83.0</td>\n",
       "      <td>34.74</td>\n",
       "      <td>51.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>87.0</td>\n",
       "      <td>4.486770e+00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>35.14</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.935285e-01</td>\n",
       "      <td>87.0</td>\n",
       "      <td>35.60</td>\n",
       "      <td>49.24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>88.0</td>\n",
       "      <td>3.720411e+00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>35.28</td>\n",
       "      <td>24.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.845362e-01</td>\n",
       "      <td>89.0</td>\n",
       "      <td>34.13</td>\n",
       "      <td>42.74</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>89.0</td>\n",
       "      <td>2.993216e+00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>34.67</td>\n",
       "      <td>26.89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.051014e-01</td>\n",
       "      <td>93.0</td>\n",
       "      <td>36.76</td>\n",
       "      <td>68.52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>90.0</td>\n",
       "      <td>2.346042e+00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.06</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.475150e-01</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.08</td>\n",
       "      <td>64.36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-10)    var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  var6(t-10)  \\\n",
       "85         86.0  6.670000e-05        95.0       23.47       61.17    0.003958   \n",
       "86         87.0  3.330000e-05        90.0       24.05       58.65    0.000208   \n",
       "87         88.0  1.660000e-05        83.0       23.69       62.14    0.000000   \n",
       "88         89.0  8.270000e-06        92.0       23.58       60.59    0.000000   \n",
       "89         90.0  4.120000e-06        96.0       24.34       65.34    0.000000   \n",
       "175        86.0  5.140000e-07        95.0       23.47       61.17    0.003958   \n",
       "176        87.0  2.050000e-07        90.0       24.05       58.65    0.000208   \n",
       "177        88.0  8.160000e-08        83.0       23.69       62.14    0.000000   \n",
       "178        89.0  3.250000e-08        92.0       23.58       60.59    0.000000   \n",
       "179        90.0  1.300000e-08        96.0       24.34       65.34    0.000000   \n",
       "265        86.0  6.157151e+00        95.0       35.89       38.49    0.000000   \n",
       "266        87.0  6.602047e+00        81.0       35.14       28.45    0.000000   \n",
       "267        88.0  6.971920e+00        73.0       35.28       24.72    0.000000   \n",
       "268        89.0  7.078277e+00        71.0       34.67       26.89    0.000000   \n",
       "269        90.0  6.547096e+00        72.0       35.06       25.65    0.000104   \n",
       "355        86.0  5.234138e+00        95.0       35.89       38.49    0.000000   \n",
       "356        87.0  4.486770e+00        81.0       35.14       28.45    0.000000   \n",
       "357        88.0  3.720411e+00        73.0       35.28       24.72    0.000000   \n",
       "358        89.0  2.993216e+00        71.0       34.67       26.89    0.000000   \n",
       "359        90.0  2.346042e+00        72.0       35.06       25.65    0.000104   \n",
       "\n",
       "     var7(t-10)  var8(t-10)  var9(t-10)  var10(t-10)     ...      var1(t-1)  \\\n",
       "85          1.0         0.0         1.0          0.0     ...           95.0   \n",
       "86          1.0         0.0         1.0          0.0     ...           96.0   \n",
       "87          1.0         0.0         1.0          0.0     ...           97.0   \n",
       "88          1.0         0.0         1.0          0.0     ...           98.0   \n",
       "89          1.0         0.0         1.0          0.0     ...           99.0   \n",
       "175         1.0         0.0         0.0          1.0     ...           95.0   \n",
       "176         1.0         0.0         0.0          1.0     ...           96.0   \n",
       "177         1.0         0.0         0.0          1.0     ...           97.0   \n",
       "178         1.0         0.0         0.0          1.0     ...           98.0   \n",
       "179         1.0         0.0         0.0          1.0     ...           99.0   \n",
       "265         0.0         1.0         1.0          0.0     ...           95.0   \n",
       "266         0.0         1.0         1.0          0.0     ...           96.0   \n",
       "267         0.0         1.0         1.0          0.0     ...           97.0   \n",
       "268         0.0         1.0         1.0          0.0     ...           98.0   \n",
       "269         0.0         1.0         1.0          0.0     ...           99.0   \n",
       "355         0.0         1.0         0.0          1.0     ...           95.0   \n",
       "356         0.0         1.0         0.0          1.0     ...           96.0   \n",
       "357         0.0         1.0         0.0          1.0     ...           97.0   \n",
       "358         0.0         1.0         0.0          1.0     ...           98.0   \n",
       "359         0.0         1.0         0.0          1.0     ...           99.0   \n",
       "\n",
       "        var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  \\\n",
       "85   1.270000e-07       76.0      25.06      67.93   0.001042        1.0   \n",
       "86   6.330000e-08       83.0      25.45      67.36   0.000417        1.0   \n",
       "87   3.160000e-08       82.0      25.60      64.60   0.000417        1.0   \n",
       "88   1.570000e-08       89.0      25.56      69.67   0.000208        1.0   \n",
       "89   7.850000e-09       89.0      29.70      81.26   0.000000        1.0   \n",
       "175  1.300000e-10       76.0      25.06      67.93   0.001042        1.0   \n",
       "176  5.180000e-11       83.0      25.45      67.36   0.000417        1.0   \n",
       "177  2.060000e-11       82.0      25.60      64.60   0.000417        1.0   \n",
       "178  8.220000e-12       89.0      25.56      69.67   0.000208        1.0   \n",
       "179  3.280000e-12       89.0      29.70      81.26   0.000000        1.0   \n",
       "265  2.222748e-01       83.0      34.74      51.59   0.000000        0.0   \n",
       "266  8.274950e-02       87.0      35.60      49.24   0.000000        0.0   \n",
       "267  3.049128e-02       89.0      34.13      42.74   0.000000        0.0   \n",
       "268  1.119251e-02       93.0      36.76      68.52   0.000000        0.0   \n",
       "269  4.102686e-03       90.0      37.08      64.36   0.000000        0.0   \n",
       "355  5.419863e-01       83.0      34.74      51.59   0.000000        0.0   \n",
       "356  3.935285e-01       87.0      35.60      49.24   0.000000        0.0   \n",
       "357  2.845362e-01       89.0      34.13      42.74   0.000000        0.0   \n",
       "358  2.051014e-01       93.0      36.76      68.52   0.000000        0.0   \n",
       "359  1.475150e-01       90.0      37.08      64.36   0.000000        0.0   \n",
       "\n",
       "     var8(t-1)  var9(t-1)  var10(t-1)  \n",
       "85         0.0        1.0         0.0  \n",
       "86         0.0        1.0         0.0  \n",
       "87         0.0        1.0         0.0  \n",
       "88         0.0        1.0         0.0  \n",
       "89         0.0        1.0         0.0  \n",
       "175        0.0        0.0         1.0  \n",
       "176        0.0        0.0         1.0  \n",
       "177        0.0        0.0         1.0  \n",
       "178        0.0        0.0         1.0  \n",
       "179        0.0        0.0         1.0  \n",
       "265        1.0        1.0         0.0  \n",
       "266        1.0        1.0         0.0  \n",
       "267        1.0        1.0         0.0  \n",
       "268        1.0        1.0         0.0  \n",
       "269        1.0        1.0         0.0  \n",
       "355        1.0        0.0         1.0  \n",
       "356        1.0        0.0         1.0  \n",
       "357        1.0        0.0         1.0  \n",
       "358        1.0        0.0         1.0  \n",
       "359        1.0        0.0         1.0  \n",
       "\n",
       "[20 rows x 100 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMER TRAIN AND TEST SPLIT APPORACH\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "y_train = np.array([])\n",
    "X_test = pd.DataFrame()\n",
    "y_test = np.array([])\n",
    "\n",
    "true_index_counter = -1\n",
    "for i in range (0, int(len(df_sf)/100)):\n",
    "    for k in range (1, 101):\n",
    "        true_index_counter += 1\n",
    "        if k <= 95:\n",
    "            X_train = X_train.append(df_sf.loc[true_index_counter].drop(['GrowthRate']))\n",
    "            y_train = np.append(y_train, df_sf.loc[true_index_counter, 'GrowthRate'])\n",
    "        else:\n",
    "            X_test = X_test.append(df_sf.loc[true_index_counter].drop(['GrowthRate']))\n",
    "            y_test = np.append(y_test, df_sf.loc[true_index_counter, 'GrowthRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(data)\n",
    "# raw = DataFrame()\n",
    "# raw['ob1'] = [x for x in range(10)]\n",
    "# raw['ob2'] = [x for x in range(50, 60)]\n",
    "# values = raw.values\n",
    "# data = series_to_supervised(values, 1, 19)\n",
    "# print(data)\n",
    "# data\n",
    "\n",
    "# X_train = data.drop(['var2(t)'], axis=1)\n",
    "# y_train = data.loc[:, 'var2(t)']\n",
    "# print([data if val == True else None for ind, val in enumerate(data.columns.str.contains('\\(t\\)'))])\n",
    "# for ind, val in enumerate(data.columns.str.contains('\\(t\\)')):\n",
    "#     if val == True:\n",
    "#         data.drop([])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for df in cycles:\n",
    "    values = df.values\n",
    "    values_supervised = series_to_supervised(values, 10, 1)\n",
    "    data = pd.concat([data, values_supervised], axis=0)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df_sf.values\n",
    "data = series_to_supervised(values,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('output_shifted_cycles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN AND TEST SPLIT\n",
    "\n",
    "X = data.loc[:,~data.columns.str.contains('\\(t\\)')]\n",
    "# X = data.drop([data.columns.str.contains('\\(t\\)')], axis=1)\n",
    "y = data.loc[:, 'var2(t)']\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.9, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns.str.contains('\\(t\\)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR COMPUTATION FUNCTIONS\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def evaluate_errors(prediction, actual):\n",
    "    print(\"RMSE Error: \", np.sqrt(mean_squared_error(prediction, actual)))\n",
    "    avg_error_vector = np.absolute(((prediction - actual) / actual) * 100)\n",
    "    print(\"Average Error details:\\n\", np.mean(avg_error_vector))\n",
    "    return avg_error_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE FUNCTIONS\n",
    "\n",
    "def get_feature_importances(regr):\n",
    "    feature_importances = regr.feature_importances_\n",
    "    feature_importances = pd.Series(feature_importances)\n",
    "    feature_importance_df = pd.DataFrame({'feature': X_train.columns,'feature_importance': feature_importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by=['feature_importance'])\n",
    "    for index, row in feature_importance_df.iterrows():\n",
    "        print(row['feature'], 'has importance: ', row['feature_importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.05035181879900358\n",
      "RMSE 0.08141561469059781\n",
      "var7(t-10) has importance:  7.779705197766933e-08\n",
      "var10(t-6) has importance:  8.624568322857439e-08\n",
      "var9(t-5) has importance:  1.0127658964550529e-07\n",
      "var10(t-9) has importance:  3.242182905383565e-07\n",
      "var10(t-1) has importance:  3.2780355002755236e-07\n",
      "var9(t-3) has importance:  5.347805579600149e-07\n",
      "var7(t-5) has importance:  5.454867764674887e-07\n",
      "var9(t-1) has importance:  6.229154230608587e-07\n",
      "var8(t-2) has importance:  7.298841791177522e-07\n",
      "var8(t-8) has importance:  8.940478972473184e-07\n",
      "var7(t-7) has importance:  1.1324108581726458e-06\n",
      "var10(t-8) has importance:  1.1471578838950498e-06\n",
      "var7(t-8) has importance:  2.199870662537143e-06\n",
      "var7(t-4) has importance:  2.6109013648232764e-06\n",
      "var8(t-1) has importance:  2.811595398879157e-06\n",
      "var9(t-2) has importance:  2.962061789803085e-06\n",
      "var10(t-5) has importance:  3.103755743187172e-06\n",
      "var9(t-10) has importance:  3.145949392675189e-06\n",
      "var7(t-2) has importance:  3.3624142372985677e-06\n",
      "var7(t-9) has importance:  3.3799921347821814e-06\n",
      "var7(t-1) has importance:  4.276827248762931e-06\n",
      "var9(t-4) has importance:  4.3306915690743315e-06\n",
      "var7(t-3) has importance:  4.615519697612285e-06\n",
      "var8(t-10) has importance:  5.312159907693216e-06\n",
      "var10(t-4) has importance:  5.587651123710342e-06\n",
      "var10(t-7) has importance:  6.061190595343581e-06\n",
      "var10(t-3) has importance:  6.401734294844571e-06\n",
      "var8(t-3) has importance:  6.65973794188131e-06\n",
      "var8(t-4) has importance:  7.059282018197644e-06\n",
      "var8(t-6) has importance:  1.135546643572126e-05\n",
      "var8(t-9) has importance:  1.3291660552141736e-05\n",
      "var10(t-10) has importance:  1.3434830165303636e-05\n",
      "var6(t-7) has importance:  1.4777723790975445e-05\n",
      "var9(t-9) has importance:  1.5153550162841078e-05\n",
      "var9(t-7) has importance:  1.6332375362769254e-05\n",
      "var9(t-8) has importance:  1.721880952564258e-05\n",
      "var9(t-6) has importance:  2.215403402579257e-05\n",
      "var8(t-5) has importance:  2.5178272768301044e-05\n",
      "var1(t-8) has importance:  3.088645887442967e-05\n",
      "var6(t-2) has importance:  3.162934107742667e-05\n",
      "var8(t-7) has importance:  3.404351913170278e-05\n",
      "var1(t-5) has importance:  3.440792024400079e-05\n",
      "var7(t-6) has importance:  3.8426898298999856e-05\n",
      "var5(t-5) has importance:  4.100414206923641e-05\n",
      "var6(t-8) has importance:  4.1450268458364145e-05\n",
      "var4(t-5) has importance:  4.275967778063945e-05\n",
      "var6(t-4) has importance:  4.35765885415123e-05\n",
      "var1(t-2) has importance:  4.6056515393957995e-05\n",
      "var1(t-10) has importance:  4.917430165152061e-05\n",
      "var1(t-3) has importance:  5.305781918332179e-05\n",
      "var4(t-2) has importance:  5.785565344820869e-05\n",
      "var5(t-2) has importance:  6.09112125671592e-05\n",
      "var10(t-2) has importance:  6.253689259411825e-05\n",
      "var6(t-6) has importance:  6.256246312110557e-05\n",
      "var4(t-6) has importance:  6.742507658545385e-05\n",
      "var3(t-2) has importance:  7.235510295789642e-05\n",
      "var5(t-9) has importance:  7.468002088407134e-05\n",
      "var5(t-1) has importance:  7.716219952150528e-05\n",
      "var6(t-10) has importance:  8.09713125981865e-05\n",
      "var1(t-9) has importance:  8.22199520437296e-05\n",
      "var4(t-1) has importance:  8.429256292028489e-05\n",
      "var1(t-6) has importance:  9.481248318434732e-05\n",
      "var6(t-5) has importance:  0.00010912243291406143\n",
      "var1(t-4) has importance:  0.00012038860263272561\n",
      "var1(t-7) has importance:  0.00012564791452755397\n",
      "var6(t-9) has importance:  0.00012809415796455036\n",
      "var6(t-3) has importance:  0.0001671401577410414\n",
      "var1(t-1) has importance:  0.0001780039815554227\n",
      "var4(t-10) has importance:  0.00019096559401059104\n",
      "var3(t-8) has importance:  0.0002165720578674325\n",
      "var5(t-8) has importance:  0.0002200156425476491\n",
      "var5(t-7) has importance:  0.00022752987022531121\n",
      "var4(t-7) has importance:  0.0002502672585121029\n",
      "var2(t-7) has importance:  0.0002688229194058639\n",
      "var5(t-3) has importance:  0.00026998670995537633\n",
      "var3(t-1) has importance:  0.0003462181085970891\n",
      "var3(t-6) has importance:  0.00034867485666363965\n",
      "var3(t-3) has importance:  0.0003516505988214437\n",
      "var5(t-6) has importance:  0.0003861910272629953\n",
      "var3(t-7) has importance:  0.0004029531855724854\n",
      "var3(t-9) has importance:  0.0004237297545333982\n",
      "var4(t-9) has importance:  0.0004869084991924835\n",
      "var4(t-8) has importance:  0.0005669798708835165\n",
      "var6(t-1) has importance:  0.0005914991471471459\n",
      "var3(t-5) has importance:  0.0005988863477506651\n",
      "var2(t-10) has importance:  0.0006195088681237254\n",
      "var5(t-10) has importance:  0.0007785063822644028\n",
      "var2(t-5) has importance:  0.0007849541730874521\n",
      "var3(t-4) has importance:  0.0007854494980164762\n",
      "var4(t-4) has importance:  0.0008202653854555953\n",
      "var2(t-8) has importance:  0.0009850209926484444\n",
      "var2(t-3) has importance:  0.0010012358313632144\n",
      "var4(t-3) has importance:  0.0010829957970019978\n",
      "var2(t-9) has importance:  0.0012223697255670475\n",
      "var3(t-10) has importance:  0.0012396742181952842\n",
      "var2(t-6) has importance:  0.0017558562579698626\n",
      "var5(t-4) has importance:  0.0018295469878781803\n",
      "var2(t-4) has importance:  0.003142385247558434\n",
      "var2(t-2) has importance:  0.006605739212375429\n",
      "var2(t-1) has importance:  0.9687766822604269\n"
     ]
    }
   ],
   "source": [
    "# MODELS RF\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(n_estimators=20, max_depth=13, random_state=0, verbose=1, n_jobs=-1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "# evaluate_errors(preds, y_test)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('MAE', mean_absolute_error(preds, y_test))\n",
    "print('RMSE', np.sqrt(mean_squared_error(preds, y_test)))\n",
    "get_feature_importances(regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([preds, y_test.astype(float).reset_index()], axis=1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[19,data.columns.str.contains('var2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS LIGHTGBM\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(n_estimators=1000, learning_rate=0.01)\n",
    "clf.fit(X_train, np.log1p(y_train))\n",
    "preds = np.expm1(clf.predict(X_test))\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(X_test)\n",
    "preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)\n",
    "errs = evaluate_errors(preds, y_train)\n",
    "print(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clf = MLPRegressor(solver='adam', activation='tanh')\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "# evaluate_errors(preds, y_test)\n",
    "# print(preds)\n",
    "# print(y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(preds, y_test))\n",
    "# get_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clf = MLPRegressor(solver='lbfgs', activation='tanh')\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "evaluate_errors(preds, y_test)\n",
    "print(preds)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS AN EXAMPLE OF A TIME SERIES PROBLEM WITH KERAS\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# # convert an array of values into a dataset matrix\n",
    "# def create_dataset(dataset, look_back=1):\n",
    "# \tdataX, dataY = [], []\n",
    "# \tfor i in range(len(dataset)-look_back-1):\n",
    "# \t\ta = dataset[i:(i+look_back), 0]\n",
    "# \t\tdataX.append(a)\n",
    "# \t\tdataY.append(dataset[i + look_back, 0])\n",
    "# \treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# # fix random seed for reproducibility\n",
    "# numpy.random.seed(7)\n",
    "# # load the dataset\n",
    "# # dataframe = read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv', engine='python', skipfooter=3)\n",
    "# dataset = dataframe.values\n",
    "# dataset = dataset.astype('float32')\n",
    "# # normalize the dataset\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# dataset = scaler.fit_transform(dataset)\n",
    "# # split into train and test sets\n",
    "# train_size = int(len(dataset) * 0.67)\n",
    "# test_size = len(dataset) - train_size\n",
    "# train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# # reshape into X=t and Y=t+1\n",
    "look_back = 12\n",
    "# trainX, trainY = create_dataset(train, look_back)\n",
    "# testX, testY = create_dataset(test, look_back)\n",
    "# # reshape input to be [samples, time steps, features]\n",
    "# trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "# testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(380, look_back)))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(X_train)\n",
    "testPredict = model.predict(X_test)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS AN EXAMPLE OF A TIME SERIES PROBLEM WITH KERAS\n",
    "\n",
    "# Stacked LSTM for international airline passengers problem with memory\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "for i in range(100):\n",
    "\tmodel.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "\tmodel.reset_states()\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "testPredict = model.predict(testX, batch_size=batch_size)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS AN EXAMPLE OF A TIME SERIES PROBLEM WITH KERAS\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima price dataset\n",
    "dataset = datasets.load_boston()\n",
    "# split into input (X) and output (Y) variables\n",
    "# X = dataset[:,0:8]\n",
    "# Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=109, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Compile model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, y_train)\n",
    "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
