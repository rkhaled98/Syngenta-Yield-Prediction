{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THERE ARE SEPARATE NOTEBOOKS FOR VISUALIZATIONS, DATASET ANALYSIS, ETC. IN THE REPO.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# READ THE CSV INTO DATAFRAME\n",
    "\n",
    "df = pd.read_csv('Syngenta/Syngenta_2017/Experiment_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Yield.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS USED WHEN CONNECTING TO COMPUTE NODES TO CHECK IF EVERYTHING IS WORKING\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 174 ADDITIONAL VARIETY COLUMNS METHOD\n",
    "\n",
    "variety_dummies = pd.get_dummies(df.Variety)\n",
    "variety_dummies.columns = [i for i in range (0,174)]\n",
    "df = pd.concat([df, variety_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull()]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY NECESSARY IF: USING 8 ADDITIONAL VARIETY COLUMNS (BINARY REPRESENTATION)\n",
    "\n",
    "UNIQUE_VARIETIES = np.unique(df.Variety)\n",
    "INDICES = [i for i in range(0, len(UNIQUE_VARIETIES))]\n",
    "# print(np.where(UNIQUE_VARIETIES=='V000017'))\n",
    "df.VarietyBin = df.Variety.apply(lambda var: np.where(UNIQUE_VARIETIES==var)[0][0])\n",
    "# print(UNIQUE_VARIETIES)\n",
    "# print(df.Variety)\n",
    "\n",
    "df.VarietyBin = df.VarietyBin.apply(lambda var: '{0:08b}'.format(var))\n",
    "print(\"done\")\n",
    "df.VarietyBin = df.VarietyBin.apply(lambda var: list(var))\n",
    "print(\"done\")\n",
    "variety_binary_df = pd.DataFrame(pd.Series(df.VarietyBin[i]) for i in range(0, len(df.VarietyBin)))\n",
    "df = pd.concat([df, variety_binary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GOAL OF THIS MODULE:\n",
    "# Encode the planting date as a season\n",
    "\n",
    "# remove the dates that are \".\"\n",
    "df = df[~df['Planting date'].str.match(\"\\.\")]\n",
    "plant_date = df['Planting date'].apply(lambda dt: pd.to_datetime(dt))\n",
    "plant_months = plant_date.apply(lambda dt: dt.month)\n",
    "season = plant_date.rename(\"Season\")\n",
    "season = pd.to_datetime(season)\n",
    "season = season.apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# df['Plant date'] = pd.to_datetime(df['Plant date'])\n",
    "df = pd.concat([df, season], axis=1)\n",
    "\n",
    "# plant_date = pd.to_datetime(df['Planting date'], infer_datetime_format=True)\n",
    "# df = df['Planting date'].apply(lambda dt: (dt.month%12 + 3)//3)\n",
    "# pd.get_dummies(df['Planting date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD MONTH OF MAY AND JUNE ONE HOT ENCODING INTO THE DATAFRAME\n",
    "pd.get_dummies(plant_months).sum()\n",
    "june = pd.get_dummies(plant_months).loc[:,6]\n",
    "june = june.rename(\"June\")\n",
    "may = pd.get_dummies(plant_months).loc[:,5]\n",
    "may = may.rename(\"May\")\n",
    "df = pd.concat([df, may], axis=1)\n",
    "df = pd.concat([df, june], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LATITUDE AND LONGITUDE CLUSTERING INTO FEATURES\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "latlong = df.loc[:, ['Latitude', 'Longitude']]\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_jobs=-1).fit(latlong)\n",
    "kmeans.labels_.shape\n",
    "lat_long_dummies = pd.get_dummies(kmeans.labels_)\n",
    "lat_long_dummies = lat_long_dummies.rename(index=int, columns={0: \"Loc Clust 0\",\n",
    "                                                               1: \"Loc Clust 1\",\n",
    "                                                               2: \"Loc Clust 2\",\n",
    "                                                               3: \"Loc Clust 3\"})\n",
    "df = pd.concat([df, lat_long_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below 3 nodes were used to generate csv for use with https://www.darrinward.com/lat-long/\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "latlong = df.loc[:, ['Latitude', 'Longitude']]\n",
    "kmeans = KMeans(n_clusters=8, random_state=0, n_jobs=-1).fit(latlong)\n",
    "dummies = pd.get_dummies(kmeans.labels_)\n",
    "dummies.columns = [\"Loc Clust \" + str(x) for x in dummies.columns]\n",
    "reformatted = dummies.idxmax(axis=1)\n",
    "latlong = pd.concat([latlong, reformatted], axis=1)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "# dummies = dummies.rename(index=int, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "colors = [\"#%06x\" % random.randint(0, 0xFFFFFF) for i in range(0,8)]\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong = latlong.rename(index=str, columns={0:\"name\"})\n",
    "colors_dict = {key:colors[int(key[-1])] for key in dummies.columns}\n",
    "latlong['color'] = latlong['name'].map(colors_dict)\n",
    "# colors.keys = [key for key in dummies.columns]\n",
    "latlongsample = latlong.sample(frac=0.01)\n",
    "latlongsample.to_csv(\"latlongsample.csv\")\n",
    "latlongsample.reindex()\n",
    "latlong.to_csv(\"latlongname.csv\")\n",
    "latlongsample.drop(['color'], axis=1).to_csv(\"latlongsamplenocolor.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE ANY NAN VALUES\n",
    "\n",
    "print(df.columns)\n",
    "df = df[~df.Silt.isnull()]\n",
    "df = df[~df['Loc Clust 1'].isnull()]\n",
    "df = df[~df['Yield'].isnull()]\n",
    "# df = df[~df['Loc Clust 0'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col, type(df[col][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP ALL THE CELLS THAT ARE NOT USABLE SUCH AS THE ONES THAT ARE STRINGS OR DATES\n",
    "\n",
    "# set if want to drop some columns specifically\n",
    "should_drop = 1\n",
    "# columns_to_drop = ['Experiment', 'Location',\n",
    "#                    'Check Yield', 'Yield difference', 'Latitude',\n",
    "#                    'Longitude', 'PI', 'Variety', 'Planting date', 'Season']\n",
    "\n",
    "# BELOW DROP IS USED FOR THE DF_DICT APPROACH\n",
    "# columns_to_drop = ['Experiment', 'Location',\n",
    "#                    'Check Yield', 'Yield difference', \n",
    "#                    'PI', 'Planting date', 'Season', 'Variety']\n",
    "# columns_to_drop = ['Experiment', 'Location',\n",
    "#                  'Check Yield', 'Yield difference', 'PI', 'Planting date', 'Variety']\n",
    "columns_to_drop = ['Experiment', 'Location',\n",
    "                 'Check Yield', 'Yield difference', 'PI', 'Planting date', 'Variety', 'Latitude', 'Longitude']\n",
    "\n",
    "# set if want to keep some columns specifically\n",
    "should_keep = 0\n",
    "# columns_to_keep = ['Loc Clust 0', 'Loc Clust 1', 'Loc Clust 2', 'Loc Clust 3']\n",
    "columns_to_keep = []\n",
    "\n",
    "# columns_to_keep_top = ['Silt', 'Precipitation', 'Temperature', 'Solar Radiation', 'Organic matter']\n",
    "# columns_VARIETIES_ONLY = np.asarray(df.iloc[:, df.columns.str.match('V\\d\\d\\d\\d\\d\\d')].columns)\n",
    "\n",
    "#set the below variable to whatever columns you want to keep\n",
    "columns_to_keep = columns_to_keep\n",
    "\n",
    "MUST_HAVE_COLUMNS = ['Yield']\n",
    "# print(columns_to_keep)\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1) if should_drop else df\n",
    "df = df.loc[:, np.concatenate((columns_to_keep, MUST_HAVE_COLUMNS))] if should_keep else df\n",
    "df['YieldBucket'] = pd.Series(pd.qcut(df.Yield, q=3, labels=[\"high\", \"medium\", \"low\"]))\n",
    "print(\"The final dataframe has columns: \", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, latlong], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,'Sand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in range(0,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET US ALSO MAKE SURE THERE ARE NO NAN IN THE DATA\n",
    "\n",
    "print(\"We expect to be %s nan values and there actually are %s nan values\\n\" % (0, np.sum(df.isnull().sum())))\n",
    "print(df.isnull().sum())\n",
    "# AFTER COLUMNS, MAKE SURE NO SKETCHY ONES\n",
    "for col in df.columns:\n",
    "    print(col, type(df[col][0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT ( NOT FOR USE WITH DICTIONARY METHOD)\n",
    "# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT# TRAIN AND TEST SPLIT ( NOT FOR USE WITH DICTIONARY METHOD)\n",
    "\n",
    "X = df.drop(['Yield', 'YieldBucket'], axis=1)\n",
    "\n",
    "# print(X.columns)\n",
    "\n",
    "y = df.Yield\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, train_size = 0.95, random_state = 42)\n",
    "\n",
    "INPUT_COLS = X_train.columns\n",
    "# TEST_COLS = y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS MODULE IS ONLY BEING USED FOR THE COMPARISON OF CUMULATIVE TRAINING WITH DICTIONARY BASED TRAINING\n",
    "X_train_varieties = X_train.Variety\n",
    "X_test_varieties = X_test.Variety\n",
    "X_train = X_train.drop(['Variety'], axis=1)\n",
    "X_test = X_test.drop(['Variety'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape, \"\\ny_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[~X_train.Temperature.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in X_train.columns:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL OF THIS MODULE: PCA OUTPUT AND VISUAL ANALYSIS\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def gen_PCA(X_train_, target_series, visualize=False):\n",
    "    # vis_features = ['Silt', 'Precipitation', 'Organic matter', 'Solar Radiation', 'Temperature', 'CEC']\n",
    "    # X_train_scaled = StandardScaler().fit_transform(X_train_.loc[:, vis_features])\n",
    "    X_train_scaled = StandardScaler().fit_transform(X_train_)\n",
    "\n",
    "    pca = PCA(n_components=8)\n",
    "    principalComponents = pca.fit_transform(X_train_scaled)\n",
    "#     principal_df = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "    principal_df = pd.DataFrame(data=principalComponents)\n",
    "    print(principal_df.shape)\n",
    "#     print(X_train_.shape)\n",
    "    print(target_series.shape)\n",
    "    \n",
    "    # WHY DOES THE BELOW LINE NOT WORK AND INSTEAD I NEED TO USE THE FOLLOWING TWO LINES?\n",
    "#     final_df = pd.concat([principal_df, target_series], axis=1)\n",
    "    final_df = principal_df\n",
    "    final_df['Yield'] = target_series\n",
    "    \n",
    "    print(final_df.shape)\n",
    "    print(final_df)\n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "        ax = fig.add_subplot(1,1,1) \n",
    "        ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "        ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "        ax.set_title('2 component PCA', fontsize = 20)\n",
    "        targets = ['high', 'medium', 'low']\n",
    "        colors = ['g', 'y', 'r']\n",
    "        for target, color in zip(targets,colors):\n",
    "            indicesToKeep = final_df['YieldBucket'] == target\n",
    "            ax.scatter(final_df.loc[indicesToKeep, 'principal component 1']\n",
    "                       , final_df.loc[indicesToKeep, 'principal component 2']\n",
    "                       , c = color\n",
    "                       , s = 3)\n",
    "        ax.legend(targets)\n",
    "        ax.grid()\n",
    "        fig.savefig(\"graphs/PCA-bucketing.png\")\n",
    "    return final_df\n",
    "    \n",
    "final_df = gen_PCA(X_train, df['Yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(X_train.columns)\n",
    "final_df.isnull().sum()\n",
    "final_df[final_df.Yield.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[~final_df.Yield.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_df.drop(['Yield'], axis=1), final_df.loc[:, 'Yield'], train_size = 0.5, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "    X_train[i] = pd.to_numeric(X_train[i])\n",
    "    X_test[i] = pd.to_numeric(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FUNCTION WILL EVALUATE ERRORS BASED ON RMSE (FROM SYNGENTA CHALLENGE SPEC)\n",
    "# AND ALSO WILL EVALUATE BASED ON AVERAGE ERROR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_errors(prediction, actual):\n",
    "    RMSE_error = np.sqrt(mean_squared_error(prediction, actual))\n",
    "    print(\"RMSE Error: \", np.sqrt(mean_squared_error(prediction, actual)))\n",
    "    avg_error_vector = np.absolute(((prediction - actual) / actual) * 100)\n",
    "    print(\"Average Error details:\\n\", avg_error_vector.describe())\n",
    "    return avg_error_vector, RMSE_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_pred, y_true): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def MAPE(prediction, actual):\n",
    "    numerator = np.abs((np.subtract(actual, prediction)))\n",
    "    denominator = prediction\n",
    "    quotient = np.divide(numerator, denominator)\n",
    "    summ = np.sum(quotient)\n",
    "    return summ/len(prediction)\n",
    "    \n",
    "# MAPE(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {}\".format(indent, tree_.value[node]))\n",
    "\n",
    "    recurse(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30],\n",
    "#     'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv=2,\n",
    "                          n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MOST USED CLASSIFIER CURRENTLY\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "regr = RandomForestRegressor(min_samples_leaf=3, min_samples_split=12,n_estimators=20, max_depth=20,random_state=32, verbose=1, n_jobs=-1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "print(\"MAE\", mean_absolute_error(preds, y_test))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(preds, y_test))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(preds, y_test)))\n",
    "# evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_df = pd.DataFrame({\n",
    "    'Variety': X_test_varieties,\n",
    "    'preds': preds,\n",
    "    'actual': y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_df.Variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {variety: variety_df.loc[variety_df.Variety == variety] for variety in UNIQUE_VARIETIES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_df_dict = {variety: df.loc[df.Variety == variety] for variety in UNIQUE_VARIETIES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in df_dict.items():\n",
    "    df_dict[key] = df.drop(['Variety'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_errs = np.array([])\n",
    "varieties = np.array([])\n",
    "\n",
    "def RMSE(preds, y_test):\n",
    "    return np.sqrt(mean_squared_error(preds, y_test))\n",
    "\n",
    "for key, df in df_dict.items():\n",
    "    RMSE_value = RMSE(df.preds, df.actual)\n",
    "    RMSE_errs = np.append(RMSE_errs, RMSE_value)\n",
    "    varieties = np.append(varieties, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'vars': varieties,\n",
    "    'errs': RMSE_errs\n",
    "}).errs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in df_dict.items():\n",
    "    if(df.shape[0] == 0):\n",
    "        print(key)\n",
    "        \n",
    "del df_dict['V152779']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "\n",
    "export_graphviz(regr.estimators_[0],\n",
    "                feature_names=X.columns,\n",
    "                filled=True,\n",
    "                rounded=True)\n",
    "\n",
    "os.system('dot -Tpng tree.dot -o tree.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open('classifier_out.txt', 'w')\n",
    "sys.stdout = f\n",
    "\n",
    "tree_to_code(regr.estimators_[0], feature_names=X_train.columns)\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET OUTPUT OF FEATURE IMPORTANCE\n",
    "\n",
    "def get_feature_importances(regr):\n",
    "    feature_importances = regr.feature_importances_\n",
    "    feature_importances = pd.Series(feature_importances)\n",
    "    feature_importance_df = pd.DataFrame({'feature': X_train.columns,'feature_importance': feature_importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by=['feature_importance'])\n",
    "    for index, row in feature_importance_df.iterrows():\n",
    "#         print(row['feature'], 'has importance: ', row['feature_importance'])\n",
    "          print(row['feature'], \",\", row['feature_importance'])\n",
    "get_feature_importances(regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(np.divide(np.subtract(y_test, preds), y_test)))\n",
    "np.sum(np.abs(np.subtract(y_test, preds))) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS LIGHTGBM\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(n_estimators=100, max_depth=25, learning_rate=0.1, n_jobs = -1, boosting_type='dart')\n",
    "# clf.fit(X_train, np.log1p(y_train))\n",
    "clf.fit(X_train, y_train)\n",
    "# preds = np.expm1(clf.predict(X_test))\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE\", mean_absolute_error(preds, y_test))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(preds, y_test))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(preds, y_test)))\n",
    "get_feature_importances(clf)\n",
    "\n",
    "# evaluate_errors(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "num_round = 10\n",
    "param = {'num_leaves':31, 'num_trees':100, 'objective':'binary'}\n",
    "param['metric'] = ['auc', 'binary_logloss']\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = []\n",
    "test_data = lgb.Dataset(test_data, reference=train_data)\n",
    "# test_data = lgb.Dataset(y_train)\n",
    "bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgbmmodel = lgb.LGBMModel(boosting_type='gbdt', num_leaves=31, max_depth=-1,\n",
    "                          learning_rate=0.1, n_estimators=1000, subsample_for_bin=200000,\n",
    "                          objective='multiclass', class_weight='balanced', min_split_gain=0.0,\n",
    "                          min_child_weight=0.001, min_child_samples=20, subsample=1.0,\n",
    "                          subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0,\n",
    "                          random_state=None, n_jobs=-1, silent=True, importance_type='split')\n",
    "\n",
    "lgbmmodel.fit(X_train, y_train, feature_name=['high','medium','low'], categorical_feature=[0,1,2])\n",
    "preds = lgbmmodel.predict(X_test)\n",
    "print(\"MAE\", mean_absolute_error(preds, y_test))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(preds, y_test))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmmodel = lgb.LGBMModel(boosting_type='gbdt', num_leaves=31, max_depth=-1,\n",
    "                          learning_rate=0.1, n_estimators=1000, subsample_for_bin=200000,\n",
    "                          objective='', class_weight=None, min_split_gain=0.0,\n",
    "                          min_child_weight=0.001, min_child_samples=20, subsample=1.0,\n",
    "                          subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0,\n",
    "                          random_state=None, n_jobs=-1, silent=True, importance_type='split')\n",
    "\n",
    "lgbmmodel.fit(X_train, y_train)\n",
    "preds = lgbmmodel.predict(X_test)\n",
    "print(\"MAE\", mean_absolute_error(preds, y_test))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(preds, y_test))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_importances(lgbmmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmmodel.dump_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dict['V000016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE AN ARRAY OF POTENTIAL CLASSIFIERS TO TEST THE PERFORMANCE OF EACH AND COMPARE\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "GRAD_BOOST_PARAMS = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "\n",
    "classifiers = [\n",
    "#     MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "#                      hidden_layer_sizes=(5, 2), random_state=1),\n",
    "#     RandomForestRegressor(n_estimators=20, max_depth=13, random_state=0, verbose=1, n_jobs=-1),\n",
    "#     linear_model.SGDRegressor(),\n",
    "#     linear_model.BayesianRidge(),\n",
    "#     linear_model.LassoLars(),\n",
    "#     linear_model.ARDRegression(),\n",
    "#     linear_model.PassiveAggressiveRegressor(),\n",
    "#     linear_model.TheilSenRegressor(),\n",
    "#     linear_model.LinearRegression(),\n",
    "#     LGBMRegressor(n_estimators=1000, learning_rate=0.01),\n",
    "#     svm.SVR(kernel=\"linear\"),\n",
    "#     linear_model.ARDRegression(),\n",
    "#     ensemble.GradientBoostingRegressor(**GRAD_BOOST_PARAMS)\n",
    "    KNeighborsRegressor(n_neighbors=11, weights='uniform',\n",
    "                        algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE CLASSIFIERS AND PREDICT ON TEST DATA\n",
    "\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "#     errors = evaluate_errors(preds, y_test)\n",
    "    print(\"MAE\", mean_absolute_error(preds, y_test))\n",
    "    print(\"MAPE\", mean_absolute_percentage_error(preds, y_test))\n",
    "    print(\"RMSE\", np.sqrt(mean_squared_error(preds, y_test)))\n",
    "    try:\n",
    "        get_feature_importances(clf)\n",
    "    except:\n",
    "        print(\"NO FEATURE IMPORTANCE METRIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS MODULE WILL OUTPUT A DICTIONARY WITH THE FEATURE RANKING OF A CLASSIFIER\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "def RFEVC_(clf, X_train_, y_train_, step_=1, verbose_=0):\n",
    "    selector = RFECV(clf, step=step_, verbose=verbose_, n_jobs=-1)\n",
    "    selector = selector.fit(X_train_, y_train_)\n",
    "    \n",
    "    INPUT_COLS = X_train.columns\n",
    "    RANKS = selector.ranking_\n",
    "\n",
    "    rank_dict = {}\n",
    "    for idx, item in enumerate(RANKS):\n",
    "        rank_dict[INPUT_COLS[idx]] = item\n",
    "    \n",
    "    import pprint\n",
    "    pprint.pprint(rank_dict)\n",
    "    \n",
    "    return rank_dict, selector\n",
    "\n",
    "# USAGE EXAMPLE:\n",
    "# rank_dict, selec = RFEVC_(regr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE RECURSIVE FEATURE ELIMINATION ON EACH CLASSIFIER IN THE ARRAY\n",
    "\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    rank_dict, selector = RFEVC_(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "NUM_VARIETIES = 174\n",
    "\n",
    "def best_yield_variety(regr, test_set, random_sel = True, n_samples = 174, print_variety_preds = True):\n",
    "    \n",
    "    #create empty df\n",
    "    dup_df = pd.DataFrame()\n",
    "    \n",
    "    #choose a rand sample of input test_set (for dev purposes, wouldn't be used in app)\n",
    "    test_set_sample = test_set.sample(n= n_samples) if random_sel else test_set\n",
    "    \n",
    "    #progress of intensive, long for loop upcoming\n",
    "    counter = 0\n",
    "    \n",
    "    #for loop will, for each row in test_set_sample, duplicate that row by NUM_VARIETIES\n",
    "    for index, row in test_set_sample.iterrows():\n",
    "        counter+=1\n",
    "        print(counter)\n",
    "        dup_df = dup_df.append([row] * NUM_VARIETIES, ignore_index = True)\n",
    "        \n",
    "    #extract the varieties columns\n",
    "    duplicated_df_varieties = dup_df.loc[:, dup_df.columns.str.match('V\\d\\d\\d\\d\\d\\d')]\n",
    "    #extract the names of the varieties\n",
    "    varieties_array = duplicated_df_varieties.columns\n",
    "    num_expanded_data_pts = duplicated_df_varieties.shape[0]\n",
    "    #we must have a zeroed matrix of the same shape as the duplicated_df_varieties\n",
    "    #so that we can input a 1 just once for each variety per 174 rows\n",
    "    d = np.zeros((duplicated_df_varieties.shape[0], NUM_VARIETIES))\n",
    "    #make d our dataframe, with columns equal to the varieties\n",
    "    duplicated_df_varieties = pd.DataFrame(d, columns=varieties_array)\n",
    "    #for loop will place a 1 just once for each variety per 174 rows (one hot rep)\n",
    "    for i in range(duplicated_df_varieties.shape[0]):\n",
    "        var_index = i % 174\n",
    "        duplicated_df_varieties.loc[i, varieties_array[var_index]] = 1\n",
    "    #remove the varieties (will be added back with the new values)\n",
    "    dup_df = dup_df.drop(varieties_array, axis = 1)\n",
    "    #add the new values (one hot representations) from above for loop\n",
    "    dup_df = pd.concat([dup_df, duplicated_df_varieties], axis=1)\n",
    "    #do prediction on the entire dataframe\n",
    "    preds_per_variety = regr.predict(dup_df)\n",
    "    #*******make it into a dataframe where each row will give the performance of each variety\n",
    "    #with the same environmental conditions*******\n",
    "    preds_df = pd.DataFrame(preds_per_variety.reshape((int(num_expanded_data_pts/NUM_VARIETIES), NUM_VARIETIES)),\n",
    "                            columns=varieties_array)\n",
    "    \n",
    "    #environmental conditions (everything except the variety data)\n",
    "    envcond = test_set_sample.drop(varieties_array, axis=1)\n",
    "    \n",
    "    #a simple print out for best variety given the environmental conditions\n",
    "    hr_preds = []\n",
    "    if print_variety_preds:\n",
    "        envcond_cols = envcond.columns\n",
    "        counter = -1\n",
    "        for idx, row in envcond.iterrows():\n",
    "            counter+=1\n",
    "            out = \"For environmental conditions:\\n%s\\nthe best variety is:%s\" % (row, preds_df.idxmax(axis=1)[counter])\n",
    "            hr_preds.append(out)\n",
    "            print(out)\n",
    "    \n",
    "    return preds_df, envcond, hr_preds\n",
    "    \n",
    "        \n",
    "preds_df, envcond, hr_preds = best_yield_variety(regr, X_test, n_samples = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of times a variety is the maximum in the above prediction dataframe\n",
    "maxes = preds_df.idxmax(axis=1) # get first max variety per env\n",
    "# print(pd.get_dummies(maxes).describe())\n",
    "print(pd.get_dummies(maxes).sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of times a variety is the maximum in the above prediction dataframe\n",
    "maxes = preds_df.idxmax(axis=1) # get first max variety per env\n",
    "# print(pd.get_dummies(maxes).describe())\n",
    "print(pd.get_dummies(maxes).sum().sort_values(ascending=False))\n",
    "print(len(pd.get_dummies(maxes).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_df.plot(kind='line', figsize=(20,20))\n",
    "# print(preds_df.loc[0].sort_values())\n",
    "# type(preds_df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_samples = preds_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_samples.plot(kind=\"area\", figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.describe().sort_values(by=\"mean\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.describe().loc['mean',:].sort_values().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION METHODS BELOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL ONLY WORK WITH THE BUCKET METHOD\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "regr = RandomForestClassifier(n_estimators=20, max_depth=20, random_state=0, verbose=1)\n",
    "regr.fit(X_train, y_train)\n",
    "preds = regr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for item in classifiers:\n",
    "    print(item)\n",
    "    clf = item\n",
    "    clf.fit(scale(X_train), y_train)\n",
    "    preds = clf.predict(scale(X_test))\n",
    "    print(accuracy_score(y_test, preds))\n",
    "#     errors = np.absolute(((preds - y_test) / y_test) * 100)\n",
    "#     print(errors)\n",
    "#     print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
